{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, precision_recall_curve, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import Imputer, LabelBinarizer, StandardScaler\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore') # To ingnore warnings entirely\n",
    "warnings.filterwarnings(action=\"once\") # To see warning only once\n",
    "TITANIC_PATH = \"/home/zhach/code/scikit_ml/datasets/titanic/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBinarizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.lb = LabelBinarizer()\n",
    "    def fit(self, X, y=None,**fit_params):\n",
    "        return self.lb.fit(X)\n",
    "    def transform(self, X):\n",
    "        return self.lb.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        a = [\"A\" in s[0] for s in X]\n",
    "        b = [\"B\" in s[0] for s in X]\n",
    "        c = [\"C\" in s[0] for s in X]\n",
    "        d = [\"D\" in s[0] for s in X]\n",
    "        e = [\"E\" in s[0] for s in X]\n",
    "        f = [\"F\" in s[0] for s in X]\n",
    "        return np.c_[a, b, c, d, e, f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Data into Program\n"
     ]
    }
   ],
   "source": [
    "tit_train = pd.read_csv(os.path.join(TITANIC_PATH, \"train.csv\"))\n",
    "y_train = tit_train[\"Survived\"]\n",
    "X_train = tit_train.drop(\"Survived\", axis=1)\n",
    "tit_test = pd.read_csv(os.path.join(TITANIC_PATH, \"test.csv\"))\n",
    "y_test = tit_test[\"Survived\"]\n",
    "X_test = tit_test.drop(\"Survived\", axis=1)\n",
    "print \"Loaded Data into Program\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 76.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId      Pclass         Age       SibSp       Parch        Fare\n",
       "count   891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
       "mean    446.000000    2.308642   29.699118    0.523008    0.381594   32.204208\n",
       "std     257.353842    0.836071   14.526497    1.102743    0.806057   49.693429\n",
       "min       1.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%     223.500000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
       "50%     446.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
       "75%     668.500000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
       "max     891.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.info()\n",
    "X_train.head()\n",
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_value = X_train['Age'].mean()\n",
    "X_train.fillna({'Age': replacement_value,\n",
    "                'Embarked': '',\n",
    "                'Cabin': ''\n",
    "               }, inplace=True)\n",
    "X_test.fillna({'Age': replacement_value,\n",
    "                'Embarked': '',\n",
    "                'Cabin': ''\n",
    "               }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribs = [\"Age\", \"SibSp\", \"Parch\", \"Fare\"]\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(num_attribs)),\n",
    "    ('imputer', Imputer(strategy='median')),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "cab_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector([\"Cabin\"])),\n",
    "    ('attribs_adder', CombinedAttributesAdder()),\n",
    "])\n",
    "\n",
    "sex_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(['Sex'])),\n",
    "    ('label_bin', CustomBinarizer()),\n",
    "])\n",
    "\n",
    "emb_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector([\"Embarked\"])),\n",
    "    ('label_bin', CustomBinarizer()),\n",
    "])\n",
    "\n",
    "pc_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector([\"Pclass\"])),\n",
    "    ('label_bin', CustomBinarizer()),\n",
    "])\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "    ('num_pipeline', num_pipeline),\n",
    "    (\"cab_pipeline\", cab_pipeline),\n",
    "    ('sex_pipeline', sex_pipeline),\n",
    "    ('emb_pipeline', emb_pipeline),\n",
    "    ('pc_pipeline', pc_pipeline),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAECCAYAAAAYUakXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFQQRCVQQRCRQQRCRQAVBRIL/AyFyI1qDSvOCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f63d5f0cc10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin A</th>\n",
       "      <th>Cabin B</th>\n",
       "      <th>Cabin C</th>\n",
       "      <th>Cabin D</th>\n",
       "      <th>Cabin E</th>\n",
       "      <th>Cabin F</th>\n",
       "      <th>Male</th>\n",
       "      <th>Embarked from Southampton</th>\n",
       "      <th>Embarked from Cherbourg</th>\n",
       "      <th>Embarked from Queenstown</th>\n",
       "      <th>P Class 1</th>\n",
       "      <th>P Class 2</th>\n",
       "      <th>P Class 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.232625</td>\n",
       "      <td>0.179191</td>\n",
       "      <td>0.091566</td>\n",
       "      <td>0.121920</td>\n",
       "      <td>0.091394</td>\n",
       "      <td>0.113149</td>\n",
       "      <td>0.132319</td>\n",
       "      <td>0.115489</td>\n",
       "      <td>0.077209</td>\n",
       "      <td>0.084153</td>\n",
       "      <td>0.032024</td>\n",
       "      <td>0.013855</td>\n",
       "      <td>0.027121</td>\n",
       "      <td>0.319916</td>\n",
       "      <td>0.006589</td>\n",
       "      <td>0.281004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.232625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>0.159651</td>\n",
       "      <td>0.046266</td>\n",
       "      <td>0.034538</td>\n",
       "      <td>0.029251</td>\n",
       "      <td>0.017575</td>\n",
       "      <td>0.033751</td>\n",
       "      <td>0.001706</td>\n",
       "      <td>0.114631</td>\n",
       "      <td>0.059528</td>\n",
       "      <td>0.026354</td>\n",
       "      <td>0.070941</td>\n",
       "      <td>0.054582</td>\n",
       "      <td>0.055932</td>\n",
       "      <td>0.092548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.179191</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.216225</td>\n",
       "      <td>0.040325</td>\n",
       "      <td>0.056498</td>\n",
       "      <td>0.030736</td>\n",
       "      <td>0.019125</td>\n",
       "      <td>0.011748</td>\n",
       "      <td>0.023694</td>\n",
       "      <td>0.245489</td>\n",
       "      <td>0.011069</td>\n",
       "      <td>0.081228</td>\n",
       "      <td>0.063036</td>\n",
       "      <td>0.017633</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>0.015790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.091566</td>\n",
       "      <td>0.159651</td>\n",
       "      <td>0.216225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019549</td>\n",
       "      <td>0.386297</td>\n",
       "      <td>0.364318</td>\n",
       "      <td>0.098878</td>\n",
       "      <td>0.051749</td>\n",
       "      <td>0.033093</td>\n",
       "      <td>0.182333</td>\n",
       "      <td>0.269335</td>\n",
       "      <td>0.117216</td>\n",
       "      <td>0.166603</td>\n",
       "      <td>0.591711</td>\n",
       "      <td>0.118557</td>\n",
       "      <td>0.413333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.121920</td>\n",
       "      <td>0.046266</td>\n",
       "      <td>0.040325</td>\n",
       "      <td>0.019549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030880</td>\n",
       "      <td>0.034846</td>\n",
       "      <td>0.025663</td>\n",
       "      <td>0.025663</td>\n",
       "      <td>0.015923</td>\n",
       "      <td>0.078271</td>\n",
       "      <td>0.093040</td>\n",
       "      <td>0.040246</td>\n",
       "      <td>0.055383</td>\n",
       "      <td>0.231323</td>\n",
       "      <td>0.066756</td>\n",
       "      <td>0.144979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.091394</td>\n",
       "      <td>0.034538</td>\n",
       "      <td>0.056498</td>\n",
       "      <td>0.386297</td>\n",
       "      <td>0.030880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062841</td>\n",
       "      <td>0.046280</td>\n",
       "      <td>0.046280</td>\n",
       "      <td>0.028715</td>\n",
       "      <td>0.109689</td>\n",
       "      <td>0.168642</td>\n",
       "      <td>0.072579</td>\n",
       "      <td>0.123057</td>\n",
       "      <td>0.417160</td>\n",
       "      <td>0.120386</td>\n",
       "      <td>0.261450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.113149</td>\n",
       "      <td>0.029251</td>\n",
       "      <td>0.030736</td>\n",
       "      <td>0.364318</td>\n",
       "      <td>0.034846</td>\n",
       "      <td>0.062841</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052225</td>\n",
       "      <td>0.052225</td>\n",
       "      <td>0.032403</td>\n",
       "      <td>0.058649</td>\n",
       "      <td>0.113952</td>\n",
       "      <td>0.049776</td>\n",
       "      <td>0.066995</td>\n",
       "      <td>0.470749</td>\n",
       "      <td>0.135851</td>\n",
       "      <td>0.295036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.132319</td>\n",
       "      <td>0.017575</td>\n",
       "      <td>0.019125</td>\n",
       "      <td>0.098878</td>\n",
       "      <td>0.025663</td>\n",
       "      <td>0.046280</td>\n",
       "      <td>0.052225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.023864</td>\n",
       "      <td>0.079248</td>\n",
       "      <td>0.102977</td>\n",
       "      <td>0.060318</td>\n",
       "      <td>0.051139</td>\n",
       "      <td>0.291218</td>\n",
       "      <td>0.041325</td>\n",
       "      <td>0.217282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.115489</td>\n",
       "      <td>0.033751</td>\n",
       "      <td>0.011748</td>\n",
       "      <td>0.051749</td>\n",
       "      <td>0.025663</td>\n",
       "      <td>0.046280</td>\n",
       "      <td>0.052225</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025699</td>\n",
       "      <td>0.054368</td>\n",
       "      <td>0.003376</td>\n",
       "      <td>0.039167</td>\n",
       "      <td>0.028520</td>\n",
       "      <td>0.235748</td>\n",
       "      <td>0.041325</td>\n",
       "      <td>0.169489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.077209</td>\n",
       "      <td>0.001706</td>\n",
       "      <td>0.023694</td>\n",
       "      <td>0.033093</td>\n",
       "      <td>0.015923</td>\n",
       "      <td>0.028715</td>\n",
       "      <td>0.032403</td>\n",
       "      <td>0.023864</td>\n",
       "      <td>0.025699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008202</td>\n",
       "      <td>0.034726</td>\n",
       "      <td>0.004113</td>\n",
       "      <td>0.033537</td>\n",
       "      <td>0.068833</td>\n",
       "      <td>0.122906</td>\n",
       "      <td>0.040721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.084153</td>\n",
       "      <td>0.114631</td>\n",
       "      <td>0.245489</td>\n",
       "      <td>0.182333</td>\n",
       "      <td>0.078271</td>\n",
       "      <td>0.109689</td>\n",
       "      <td>0.058649</td>\n",
       "      <td>0.079248</td>\n",
       "      <td>0.054368</td>\n",
       "      <td>0.008202</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082853</td>\n",
       "      <td>0.074115</td>\n",
       "      <td>0.125722</td>\n",
       "      <td>0.098013</td>\n",
       "      <td>0.064746</td>\n",
       "      <td>0.137143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.032024</td>\n",
       "      <td>0.059528</td>\n",
       "      <td>0.011069</td>\n",
       "      <td>0.269335</td>\n",
       "      <td>0.093040</td>\n",
       "      <td>0.168642</td>\n",
       "      <td>0.113952</td>\n",
       "      <td>0.102977</td>\n",
       "      <td>0.003376</td>\n",
       "      <td>0.034726</td>\n",
       "      <td>0.082853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.148258</td>\n",
       "      <td>0.778359</td>\n",
       "      <td>0.296423</td>\n",
       "      <td>0.125416</td>\n",
       "      <td>0.153329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.013855</td>\n",
       "      <td>0.026354</td>\n",
       "      <td>0.081228</td>\n",
       "      <td>0.117216</td>\n",
       "      <td>0.040246</td>\n",
       "      <td>0.072579</td>\n",
       "      <td>0.049776</td>\n",
       "      <td>0.060318</td>\n",
       "      <td>0.039167</td>\n",
       "      <td>0.004113</td>\n",
       "      <td>0.074115</td>\n",
       "      <td>0.148258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.496624</td>\n",
       "      <td>0.155342</td>\n",
       "      <td>0.127301</td>\n",
       "      <td>0.237449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.027121</td>\n",
       "      <td>0.070941</td>\n",
       "      <td>0.063036</td>\n",
       "      <td>0.166603</td>\n",
       "      <td>0.055383</td>\n",
       "      <td>0.123057</td>\n",
       "      <td>0.066995</td>\n",
       "      <td>0.051139</td>\n",
       "      <td>0.028520</td>\n",
       "      <td>0.033537</td>\n",
       "      <td>0.125722</td>\n",
       "      <td>0.778359</td>\n",
       "      <td>0.496624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170379</td>\n",
       "      <td>0.192061</td>\n",
       "      <td>0.009511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.319916</td>\n",
       "      <td>0.054582</td>\n",
       "      <td>0.017633</td>\n",
       "      <td>0.591711</td>\n",
       "      <td>0.231323</td>\n",
       "      <td>0.417160</td>\n",
       "      <td>0.470749</td>\n",
       "      <td>0.291218</td>\n",
       "      <td>0.235748</td>\n",
       "      <td>0.068833</td>\n",
       "      <td>0.098013</td>\n",
       "      <td>0.296423</td>\n",
       "      <td>0.155342</td>\n",
       "      <td>0.170379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288585</td>\n",
       "      <td>0.626738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.006589</td>\n",
       "      <td>0.055932</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>0.118557</td>\n",
       "      <td>0.066756</td>\n",
       "      <td>0.120386</td>\n",
       "      <td>0.135851</td>\n",
       "      <td>0.041325</td>\n",
       "      <td>0.041325</td>\n",
       "      <td>0.122906</td>\n",
       "      <td>0.064746</td>\n",
       "      <td>0.125416</td>\n",
       "      <td>0.127301</td>\n",
       "      <td>0.192061</td>\n",
       "      <td>0.288585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.565210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.281004</td>\n",
       "      <td>0.092548</td>\n",
       "      <td>0.015790</td>\n",
       "      <td>0.413333</td>\n",
       "      <td>0.144979</td>\n",
       "      <td>0.261450</td>\n",
       "      <td>0.295036</td>\n",
       "      <td>0.217282</td>\n",
       "      <td>0.169489</td>\n",
       "      <td>0.040721</td>\n",
       "      <td>0.137143</td>\n",
       "      <td>0.153329</td>\n",
       "      <td>0.237449</td>\n",
       "      <td>0.009511</td>\n",
       "      <td>0.626738</td>\n",
       "      <td>0.565210</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Age     SibSp     Parch      Fare   Cabin A   Cabin B   Cabin C  \\\n",
       "0   0.000000  0.232625  0.179191  0.091566  0.121920  0.091394  0.113149   \n",
       "1   0.232625  0.000000  0.414838  0.159651  0.046266  0.034538  0.029251   \n",
       "2   0.179191  0.414838  0.000000  0.216225  0.040325  0.056498  0.030736   \n",
       "3   0.091566  0.159651  0.216225  0.000000  0.019549  0.386297  0.364318   \n",
       "4   0.121920  0.046266  0.040325  0.019549  0.000000  0.030880  0.034846   \n",
       "5   0.091394  0.034538  0.056498  0.386297  0.030880  0.000000  0.062841   \n",
       "6   0.113149  0.029251  0.030736  0.364318  0.034846  0.062841  0.000000   \n",
       "7   0.132319  0.017575  0.019125  0.098878  0.025663  0.046280  0.052225   \n",
       "8   0.115489  0.033751  0.011748  0.051749  0.025663  0.046280  0.052225   \n",
       "9   0.077209  0.001706  0.023694  0.033093  0.015923  0.028715  0.032403   \n",
       "10  0.084153  0.114631  0.245489  0.182333  0.078271  0.109689  0.058649   \n",
       "11  0.032024  0.059528  0.011069  0.269335  0.093040  0.168642  0.113952   \n",
       "12  0.013855  0.026354  0.081228  0.117216  0.040246  0.072579  0.049776   \n",
       "13  0.027121  0.070941  0.063036  0.166603  0.055383  0.123057  0.066995   \n",
       "14  0.319916  0.054582  0.017633  0.591711  0.231323  0.417160  0.470749   \n",
       "15  0.006589  0.055932  0.000734  0.118557  0.066756  0.120386  0.135851   \n",
       "16  0.281004  0.092548  0.015790  0.413333  0.144979  0.261450  0.295036   \n",
       "\n",
       "     Cabin D   Cabin E   Cabin F      Male  Embarked from Southampton  \\\n",
       "0   0.132319  0.115489  0.077209  0.084153                   0.032024   \n",
       "1   0.017575  0.033751  0.001706  0.114631                   0.059528   \n",
       "2   0.019125  0.011748  0.023694  0.245489                   0.011069   \n",
       "3   0.098878  0.051749  0.033093  0.182333                   0.269335   \n",
       "4   0.025663  0.025663  0.015923  0.078271                   0.093040   \n",
       "5   0.046280  0.046280  0.028715  0.109689                   0.168642   \n",
       "6   0.052225  0.052225  0.032403  0.058649                   0.113952   \n",
       "7   0.000000  0.038462  0.023864  0.079248                   0.102977   \n",
       "8   0.038462  0.000000  0.025699  0.054368                   0.003376   \n",
       "9   0.023864  0.025699  0.000000  0.008202                   0.034726   \n",
       "10  0.079248  0.054368  0.008202  0.000000                   0.082853   \n",
       "11  0.102977  0.003376  0.034726  0.082853                   0.000000   \n",
       "12  0.060318  0.039167  0.004113  0.074115                   0.148258   \n",
       "13  0.051139  0.028520  0.033537  0.125722                   0.778359   \n",
       "14  0.291218  0.235748  0.068833  0.098013                   0.296423   \n",
       "15  0.041325  0.041325  0.122906  0.064746                   0.125416   \n",
       "16  0.217282  0.169489  0.040721  0.137143                   0.153329   \n",
       "\n",
       "    Embarked from Cherbourg  Embarked from Queenstown  P Class 1  P Class 2  \\\n",
       "0                  0.013855                  0.027121   0.319916   0.006589   \n",
       "1                  0.026354                  0.070941   0.054582   0.055932   \n",
       "2                  0.081228                  0.063036   0.017633   0.000734   \n",
       "3                  0.117216                  0.166603   0.591711   0.118557   \n",
       "4                  0.040246                  0.055383   0.231323   0.066756   \n",
       "5                  0.072579                  0.123057   0.417160   0.120386   \n",
       "6                  0.049776                  0.066995   0.470749   0.135851   \n",
       "7                  0.060318                  0.051139   0.291218   0.041325   \n",
       "8                  0.039167                  0.028520   0.235748   0.041325   \n",
       "9                  0.004113                  0.033537   0.068833   0.122906   \n",
       "10                 0.074115                  0.125722   0.098013   0.064746   \n",
       "11                 0.148258                  0.778359   0.296423   0.125416   \n",
       "12                 0.000000                  0.496624   0.155342   0.127301   \n",
       "13                 0.496624                  0.000000   0.170379   0.192061   \n",
       "14                 0.155342                  0.170379   0.000000   0.288585   \n",
       "15                 0.127301                  0.192061   0.288585   0.000000   \n",
       "16                 0.237449                  0.009511   0.626738   0.565210   \n",
       "\n",
       "    P Class 3  \n",
       "0    0.281004  \n",
       "1    0.092548  \n",
       "2    0.015790  \n",
       "3    0.413333  \n",
       "4    0.144979  \n",
       "5    0.261450  \n",
       "6    0.295036  \n",
       "7    0.217282  \n",
       "8    0.169489  \n",
       "9    0.040721  \n",
       "10   0.137143  \n",
       "11   0.153329  \n",
       "12   0.237449  \n",
       "13   0.009511  \n",
       "14   0.626738  \n",
       "15   0.565210  \n",
       "16   0.000000  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_pipeline.fit(X_train)\n",
    "attribs = [\"Age\", \"SibSp\", \"Parch\", \"Fare\", \n",
    "           \"Cabin A\", \"Cabin B\", \"Cabin C\", \"Cabin D\", \"Cabin E\", \"Cabin F\", \n",
    "           \"Male\", \n",
    "           \"Embarked from Southampton\", \"Embarked from Cherbourg\", \"Embarked from Queenstown\",\n",
    "           \"P Class 1\", \"P Class 2\", \"P Class 3\"\n",
    "          ]\n",
    "X_train_prepared = full_pipeline.transform(X_train)\n",
    "X_train_prepared = np.c_[X_train_prepared[:,:11], X_train_prepared[:,12:]]\n",
    "X_train_prepared_pd = pd.DataFrame(X_train_prepared)\n",
    "X_train_prepared_pd.columns = attribs\n",
    "corr_mat = X_train_prepared_pd.corr().abs().values\n",
    "np.fill_diagonal(corr_mat, 0)\n",
    "pd_t = pd.DataFrame(corr_mat)\n",
    "pd_t.columns = attribs\n",
    "plt.matshow(pd_t, cmap=plt.cm.gray)\n",
    "plt.show()\n",
    "pd_t\n",
    "# X_train_prepared_pd.iloc[1]\n",
    "# np.fill_diagonal(X_train_prepared_pd.corr().abs(), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def please_precision_recall_f1(clf, X, y, cv):\n",
    "    y_pred = cross_val_predict(clf, X, y, cv=cv)\n",
    "    precision = precision_score(y, y_pred)\n",
    "    recall = recall_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred, average=\"macro\")\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest Accuracy: 0.808164481927\n",
      "SGD Accuracy 0.708458936792\n",
      "KNN Accuracy 0.793582281215\n",
      "Forest PRF1: (0.75548589341692785, 0.70467836257309946, 0.78475966320324009)\n",
      "SGD PRF1 (0.65349544072948329, 0.62865497076023391, 0.71195644154579396)\n",
      "KNN PRF1 (0.75320512820512819, 0.6871345029239766, 0.77776693343743908)\n"
     ]
    }
   ],
   "source": [
    "for_clf = RandomForestClassifier()\n",
    "sgd_clf = SGDClassifier()\n",
    "knn_clf = KNeighborsClassifier()\n",
    "\n",
    "print \"Forest Accuracy:\", cross_val_score(for_clf, X_train_prepared, y_train, cv=5, scoring=\"accuracy\").mean()\n",
    "print \"SGD Accuracy\", cross_val_score(sgd_clf, X_train_prepared, y_train, cv=5, scoring=\"accuracy\").mean()\n",
    "print \"KNN Accuracy\", cross_val_score(knn_clf, X_train_prepared, y_train, cv=5, scoring=\"accuracy\").mean()\n",
    "print \"Forest PRF1:\", please_precision_recall_f1(for_clf, X_train_prepared, y_train, 5)\n",
    "print \"SGD PRF1\", please_precision_recall_f1(sgd_clf, X_train_prepared, y_train, 5)\n",
    "print \"KNN PRF1\", please_precision_recall_f1(knn_clf, X_train_prepared, y_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.796650717703 0.721854304636 0.717105263158 0.779998637762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.24139137244126338, 'Age'),\n",
       " (0.23093160907351282, 'Male'),\n",
       " (0.21869790481493787, 'Fare'),\n",
       " (0.084350216255038191, 'P Class 3'),\n",
       " (0.046078458368085065, 'SibSp'),\n",
       " (0.035456704436973671, 'Parch'),\n",
       " (0.02785026731503178, 'P Class 1'),\n",
       " (0.019245055621398922, 'Embarked from Southampton'),\n",
       " (0.017964082776884785, 'Embarked from Queenstown'),\n",
       " (0.01374531928994871, 'Cabin E'),\n",
       " (0.013734203667651056, 'Embarked from Cherbourg'),\n",
       " (0.012221848526579546, 'Cabin B'),\n",
       " (0.011267560547926402, 'Cabin C'),\n",
       " (0.0099229336663017448, 'P Class 2'),\n",
       " (0.0083570712674380307, 'Cabin D'),\n",
       " (0.0054073309377985516, 'Cabin F'),\n",
       " (0.0033780609932295043, 'Cabin A')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attribs = [\"Age\", \"SibSp\", \"Parch\", \"Fare\", \n",
    "           \"Cabin A\", \"Cabin B\", \"Cabin C\", \"Cabin D\", \"Cabin E\", \"Cabin F\", \n",
    "           \"Male\", \n",
    "           \"Embarked from Southampton\", \"Embarked from Cherbourg\", \"Embarked from Queenstown\",\n",
    "           \"P Class 1\", \"P Class 2\", \"P Class 3\"\n",
    "          ]\n",
    "best_feats = [\"\"]\n",
    "X_test_prepared = full_pipeline.transform(X_test)\n",
    "X_test_prepared = np.c_[X_test_prepared[:,:11], X_test_prepared[:,12:]]\n",
    "\n",
    "for_clf.fit(X_train_prepared, y_train)\n",
    "y_pred = for_clf.predict(X_test_prepared)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "print accuracy, precision, recall, f1\n",
    "sorted(zip(for_clf.feature_importances_, attribs), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
