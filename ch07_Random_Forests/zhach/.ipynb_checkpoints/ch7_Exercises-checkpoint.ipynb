{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore') # To ingnore warnings entirely\n",
    "warnings.filterwarnings(action=\"once\") # To see warning only once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "Is there any chance that you can combine models with high accuracy to get better results.\n",
    "Si. Law of Large Numbers, bitch.\n",
    "\n",
    "### Exercise 2\n",
    "Hard voting is by highest count, Soft voting is by average.\n",
    "\n",
    "### Exercise 3\n",
    "To get performance enhancements, the parts of training that needs to be split need to be independent of each other. The bagging, pasting, and random forests can be sped up with distributed services, because they all thrain different models at the same time. But boosting and stacking ensembles can't. Boosting required previous models to enhance their own and stacking requires the last layer to enhance their own. Distributing the training per stacking layer would enhance performance though.\n",
    "\n",
    "### Exercise 4\n",
    "The benefit of out-of-the-bag evaluations is you get a testing set out of the box since each predictor samples a part of the training set, the other part can be used as a testing set for the same model.\n",
    "\n",
    "### Exercise 5\n",
    "Extra-trees are different from Random Forests because instead of finding the optimal split for features, ETs pick random values to make trees. ETs are usually very easy to train, but they generally underfit the data.\n",
    "\n",
    "### Exercise 6\n",
    "If an AdaBoost is underfitting the data, one would increase the learning parameters. \n",
    "\n",
    "### Exercise 7\n",
    "You should decrease the learning rate if your gradient boosting ensemble is overfitting your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data in memory\n"
     ]
    }
   ],
   "source": [
    "### Exercise 8\n",
    "mnist = fetch_mldata(\"MNIST original\")\n",
    "X,y = mnist[\"data\"], mnist[\"target\"]\n",
    "shuffle_index = np.random.permutation(len(X))\n",
    "X, y = X[shuffle_index], y[shuffle_index]\n",
    "tr = int((2.0/3.0)*len(X))\n",
    "te = int((1.0/6.0)*len(X))\n",
    "X_train, X_test, X_val, y_train, y_test, y_val = X[:tr], X[tr:tr+te], X[tr+te:], y[:tr], y[tr:tr+te], y[tr+te:]\n",
    "print \"Data in memory\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhach/miniconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_we...='l2', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False))],\n",
       "         flatten_transform=None, n_jobs=1, voting='hard', weights=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_clf = RandomForestClassifier()\n",
    "gnb_clf = GaussianNB()\n",
    "sgd_clf = SGDClassifier()\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('rf', rnd_clf), ('gbn', gnb_clf), ('sgd', sgd_clf)],\n",
    "    voting='hard'\n",
    ")\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('RandomForestClassifier', 0.94472060335961605)\n",
      "('GaussianNB', 0.56847788824134382)\n",
      "('SGDClassifier', 0.84127528282482)\n",
      "('VotingClassifier', 0.89938292766540961)\n"
     ]
    }
   ],
   "source": [
    "for clf in (rnd_clf, gnb_clf, sgd_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_val)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('RandomForestClassifier', 0.89482256128921656)\n"
     ]
    }
   ],
   "source": [
    "rnd_pred = [rnd_clf.predict(X_val)]\n",
    "gnb_pred = [gnb_clf.predict(X_val)]\n",
    "sgd_pred = [sgd_clf.predict(X_val)]\n",
    "X_blend = np.concatenate((rnd_pred, gnb_pred, sgd_pred), axis=0).T\n",
    "blender = RandomForestClassifier()\n",
    "blender.fit(X_blend, y_val)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(blender.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
